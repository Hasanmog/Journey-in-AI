{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9q7cCdqDCjHw"
      },
      "outputs": [],
      "source": [
        "# AutoGrad Tutorial\n",
        "import torch\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "model = resnet18(weights=ResNet18_Weights.DEFAULT)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.rand(1,3,64,64)\n",
        "labels = torch.rand(1,1000)"
      ],
      "metadata": {
        "id": "ure0Rs50Dzsj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model(data) # forward pass\n",
        "loss = (labels - prediction).sum()\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh4ZrOoGED3z",
        "outputId": "78908f77-2bab-48a5-872d-01e3ca8d3810"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(511.2424, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward() # backward pass"
      ],
      "metadata": {
        "id": "cpxCUQHUFpzI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.9)"
      ],
      "metadata": {
        "id": "U5i48Og_FYq5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.step() #The optimizer adjusts each parameter by its gradient stored in .grad"
      ],
      "metadata": {
        "id": "cSLOCNhKGIdT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Differentiation in Autograd\n",
        "a = torch.tensor([2. , 3.] , requires_grad=True)\n",
        "b = torch.tensor([4. , 5.] , requires_grad=True)"
      ],
      "metadata": {
        "id": "GY48rXsKGcAo"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q = 3*a**3 - b**2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpqziZp0HLbx",
        "outputId": "d23dc62a-4fdc-41a9-9c9b-4ea4608af363"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 8., 56.], grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let’s assume a and b to be parameters of an NN, and Q to be the error. \n",
        "#In NN training, we want gradients of the error w.r.t. parameters, i.e.\n",
        "#When we call .backward() on Q, autograd calculates these gradients and \n",
        "#stores them in the respective tensors’ .grad attribute.\n",
        "external_grad = torch.tensor([1.,1.])\n",
        "Q.backward(gradient = external_grad)"
      ],
      "metadata": {
        "id": "B9F-vZnBHUFJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(9*a**2 == a.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAs2VfyBIO_Y",
        "outputId": "48925ab8-f7f9-40ae-867e-d6185640f733"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet18(weights= ResNet18_Weights.DEFAULT)\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False #Freeze all the parameters in the network"
      ],
      "metadata": {
        "id": "Zq_wSusaJI5q"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = torch.nn.Linear(512,10)# only parameters of this data are not frozen"
      ],
      "metadata": {
        "id": "UcjzDhcbJ5i5"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Optimizer = torch.optim.SGD(model.parameters() , lr=0.01 , momentum = 0.9)\n",
        "# This optimizer only gets the gradients of the parameters of the classifier model.fc which is the replacement of the\n",
        "# last layer (classifier ) of the pretrained model resnet18"
      ],
      "metadata": {
        "id": "0UsV6CtRKTj4"
      },
      "execution_count": 58,
      "outputs": []
    }
  ]
}